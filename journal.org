#+TITLE: KARITECH
#+AUTHOR: Shigeki Karita
#+LANGUAGE: ja

# THEMES (uncomment one block) #

# org.css
#+OPTIONS: toc:t num:nil H:4 ^:nil pri:t author:t creator:t timestamp:t email:nil
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/org.css"/>

#+BEGIN_abstract
#+BEGIN_center
ライフログ的な...
#+END_center
#+END_abstract

[[file:index.html][index]]


* 2018年01月20日 Cooperative groupsを触る                              :cuda:

  動的にthreadを構成するアルゴリズム(データの共有，集約操作など)にはthreadの同期が必須である．
  CUDA8までは， ~__syncthreads()~ 関数を用いていた: [[https://goo.gl/3SKFJu][行列乗算の例]]
  ただし，threadをblockサイズより小さくする必要が有りました．
  CUDA9では， ~cooperative_groups~ という新たなAPIが追加され


** 付録1. CUDA における thread と block の関係

   CUDAではthread < block < grid階層構造になっており，以下のようなハードウェアに起因する特徴があります．
   
   - gridが1つはkernel関数が扱える全thread集合のこと，グローバルなメモリを共有する
   - kernel関数は ~func<<< grid_size, block_size >>>(data)~ のような感じで実行する
   - サイズはそれぞれ1-3次元で指定できる
   - よくある1次元サイズの決め方は並行処理したい ~data~ 配列の要素数 ~data_size~ と性能の良い ~block_size~ に対して以下
#+begin_src cuda
#include <iostream>
#include <thrust/device_vector.h>

__global__ void iota(float* data) {
    auto i = threadIdx.x + blockIdx.x * blockDim.x;
    data[i] = i;
}

int main() {
    thrust::device_vector<float> data(100);
    dim3 block_size(32, 1, 1);
    dim3 grid_size((data.size() + block_size.x - 1) / block_size.x, 1, 1);
    iota<<<block_size, grid_size>>>(thrust::raw_pointer_cast(data.data()));
    for (auto d : data) {
        std::cout << d << std::endl;
    }
}
#+end_src
   - blockは1つのSM((Streaming Multiprocessor)が実行する単位
   - 異なるblockに属する(=異なるSMで実行される)threadは協調できない
   - 1 block に入る thread 数 (~block_size~) はハードウェア毎に上限がある
#+begin_src c
cudaDeviceProp prop;
cudaGetDeviceProperties(&prop, 0); // 0番目デバイスの情報取得
int max_block_size = prop.maxThreadsPerBlock; // 1024とか
#+end_src

   よくある性能を引き出すガイドラインとして，SMは「32スレッド」単位で実行するため，
   うまく32に収まるようblockサイズを設定することが推奨されています．

* 2018年01月16日 C++でネストした要素型の取得                            :cpp:

ごくまれにC++で 
#+begin_src c++
std::vector<std::vector<float>>
#+end_src
のようなネストした型の最後の要素 (ここでは float) を取得したいことがある．
D言語のように後方参照可能な型システムでは， [[https://github.com/libmir/numir/blob/83dbfe883b5421ba5dcf782cef272f8d205907a6/source/numir/core.d#L195-L205][再帰的に型を辿れば簡単]] だが，
#+begin_src d
template NestedElementType(T) {
    static if (isArray!T) {
        alias NestedElementType = NestedElementType!(ElementType!T);
    } else {
        alias NestedElementType = T;
    }
}
#+end_src
C++ではそうはいかない．しかし， ~constexpr~ を使えば間接的に型の再帰的な操作が可能になる．
#+begin_src C++

/* 対象のContainer型は .begin() メソッドで最初の要素を返すとする

   通常，型は再帰できない
 template <typename E>
 using DeepElementTypeof = std::conditional_t<std::is_fundamental<E>::value,
     E, DeepElementTypeof<decltype(*std::declval<E>().begin())>>;
*/

// SFINAEとcostexprならできる
#include <type_traits>
#include <vector>

template <typename E>
constexpr bool is_element = std::is_fundamental<E>::value;

template <typename E>
constexpr std::enable_if_t<is_element<E>, E> deep_elem(E) {
    return E{};
}

template <typename Container, typename _ = std::enable_if_t<!is_element<Container>>>
constexpr auto deep_elem(Container il) {
    return deep_elem(*il.begin());
}

template <typename E>
using DeepElementTypeof = std::remove_cv_t<decltype(deep_elem(std::declval<E>()))>;

std::vector<std::vector<float>> c;
static_assert(std::is_same<DeepElementTypeof<decltype(c)>, float>::value);

int main() {}
#+end_src
多次元配列を一次元配列に変換する関数なんかに便利だ．
注意したいのは，このコードではfundamental型しか最終要素として見なさない．例えば ~std::complex<float>~ などはコンパイルエラーになるだろうが， ~constexpr bool is_element = ...~ を適切に定義すれば良いはずだ．

* 2018年01月02日 おけましておめでとうございます.                      :emacs:

どうもここ二年は殆ど技術ブログを更新できませんでした。幾つか原因を考えたところ

1. Markdownがしんどい (細かい方言、Github,MDWiki,Jekyllで微妙に仕様が違う)
2. C++/CUDA(のような膨大な知識を要求する言語)をあまり書かなくなってネタが少ない

ということが挙げられます。私にとってMarkdownを使ってブログを書くのは表現力の低さ(文法ハイライトや数式表示に外部ツールが必要)、
とくにJekyll保守の面がしんどかったのです...。
そこで、何気なくEmacsに標準で付属しているorg-modeを試したところ、良さげだったので移行しました。
日常的にも仕事のメモで使っているのですが、不満は全く無く、Markdownに対する利点としては

- Emacsさえあれば環境構築は完了
- なんとなくMarkdownに文法が似てplain-textでも読み書きしやすい
- Emacsで文法ハイライトできる言語は全て対応されるので最強(Pygmentsなどがいらない)
- 表計算や表の整形もお手軽
- HTML出力(~C-c C-e h h~ で一発変換)ではMathjaxの数式組版も標準でサポート
- ~org-md-export-to-markdown~ でMarkdownへ出力できる(!)
- ODT//TeX/PDF出力もお手軽。Pandocは要りません。

という唯一無二なツールでした。標準以外の機能としてはこんなものを使っています

- 雑記用に [[https://github.com/bastibe/org-journal][org-journal]] という自動で日時付きの見出しをorgファイルに挿入するパッケージ
- Mathjaxが古いので、[[http://docs.mathjax.org/en/latest/installation.html][最新版]] DLして使っています。(数式番号が振られます)
- HTML出力が味気ないので、[[file:css/org.css][公式ページのCSSを改造]] して使っています。
- HTML出力をリアルタイム更新でモニタするために [[https://www.browsersync.io/][browser-sync]] を使っています。(例: ~browser-sync start --server --files **/*.html~ )

その他の細かい設定としてはこんな事をしてます。
#+begin_src elisp
  ;; org-journal をブログ用のリポジトリに1ファイルでまとめる
  (setq org-journal-date-format "%x")
  (setq org-journal-time-format "<%Y-%m-%d %R> ")
  (setq org-journal-file-format "journal.org")
  (setq org-journal-dir "~/Documents/repos/shigekikarita.github.io/")

  ;; org-mode からバッファ移動のコマンドを取り戻す
  (add-hook 'org-shiftup-final-hook 'windmove-up)
  (add-hook 'org-shiftleft-final-hook 'windmove-left)
  (add-hook 'org-shiftdown-final-hook 'windmove-down)
  (add-hook 'org-shiftright-final-hook 'windmove-right)

  ;; org-mode は行の折り返しなしモードになるので、無効にする
  (setq org-startup-truncated nil)

  ;; 日本語PDFのためにlualatex他、便利TeXパッケージを使う
  (setq org-latex-classes '(("ltjsarticle"
"\\documentclass{ltjsarticle}
\\usepackage{url}
\\usepackage{amsmath}
\\usepackage{newtxtext,newtxmath}
\\usepackage{graphicx}
\\usepackage{luatexja}
\\usepackage{hyperref}
 [NO-DEFAULT-PACKAGES]
 [PACKAGES]
 [EXTRA]"
            ("\\section{%s}" . "\\section*{%s}")
            ("\\subsection{%s}" . "\\subsection*{%s}")
            ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
            ("\\paragraph{%s}" . "\\paragraph*{%s}")
            ("\\subparagraph{%s}" . "\\subparagraph*{%s}"))
               ))
  (setq org-latex-pdf-process '("latexmk -gg -lualatex %f"))
  (setq org-latex-default-class "ltjsarticle")
#+end_src

あとC++/CUDAも1,2年離れていたのですが、仕事でまた使うようになり、
リハビリがてらC++17対応の [[http://www.tmplbook.com/][C++ Template Complete Guide]] を読み進めているので、
面白いネタがあれば紹介しようと思います。

それでは、今年も宜しくお願いします。







** <2018-01-20 10:56> 
