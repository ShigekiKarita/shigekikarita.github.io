<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="ja" xml:lang="ja">
<head>
<!-- 2018-12-01 土 16:46 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>1ヶ月で1から作るD言語のDeep Learningライブラリ</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Shigeki Karita" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="css/org.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">1ヶ月で1から作るD言語のDeep Learningライブラリ</h1>
<div id="table-of-contents">
<h2>&#30446;&#27425;</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org1d666c5">1. 背景とD言語 (1日目, 5/7)</a></li>
<li><a href="#org0056121">2. CPUホスト・CUDAデバイスそれぞれのメモリ管理 (2日目, 5/8)</a></li>
<li><a href="#orgc4b66c3">3. 虚無 (3日目, 5/9)</a></li>
<li><a href="#org38af46b">4. CPUホスト・CUDAデバイス両対応な関数オブジェクト (4日目, 5/10)</a>
<ul>
<li><a href="#org1022bc7">4.1. Function 関数オブジェクト</a></li>
<li><a href="#org259964c">4.2. BLASライブラリの導入</a></li>
</ul>
</li>
<li><a href="#org83d5131">5. シンプルな自動微分メカニズムと型消去 (5日目, 5/11)</a>
<ul>
<li><a href="#orgab11bde">5.1. 自動微分の仕組み</a></li>
<li><a href="#org02bffe5">5.2. 変数 Variable の仕組み</a></li>
</ul>
</li>
<li><a href="#orgc0bc52d">6. BackPropの実装とテスト (6日目, 5/12)</a>
<ul>
<li><a href="#org8c52218">6.1. BackProp の実装</a></li>
</ul>
</li>
<li><a href="#org953999b">7. 手書き文字認識MNISTの実行 (7日目, 5/13)</a></li>
<li><a href="#orgc09d6b1">8. <span class="todo TODO">TODO</span> 残った課題</a></li>
</ul>
</div>
</div>
<div class="abstract">
<p>
いまD言語が熱い．D言語はC, C++やRustの代替となるべく，日々改良が重ねられテンプレートやモジュール，ガベージコレクション(GC)などのリッチな言語機能と，C/C++との互換性・同等の速さ・フットプリントの小ささを両立しています．最近ではCUDAライブラリのラッパーが充実し，LDCコンパイラではCUDA kernelが書けるようになりました．さらにnumpyのように多次元配列を自在に扱えるMirも登場しました．というわけでディープラーニング用のライブラリを書こうと思いました．
</p>

</div>

<div id="outline-container-org1d666c5" class="outline-2">
<h2 id="org1d666c5"><span class="section-number-2">1</span> 背景とD言語 (1日目, 5/7)</h2>
<div class="outline-text-2" id="text-1">
<p>
私は勤務先で日頃からC++でクローズドなDeep Learningライブラリを一人で作っていました．CPUホストコードではC++17をCUDAデバイスコードではC++14を使っていたので，型安全にジェネリックなコードを書き，shared_ptrを使って安全にコードを書いていましたが，ときどき循環参照を起こしてメモリリークを起こしてGCが欲しくなったり，SFINAEに頼ってジェネリックなコードを書くのに辛くなってきました．そんな中でGCがあり，SFINAEに頼らない簡単・自然なメタプログラミング機能を使えるD言語を使いたい気持ちは日に日に高まっていきました．
</p>

<p>
そんな中，10連休に及ぶGWは仕事のことは忘れて虚無に過ごしたのですが，最終日に突如として<a href="https://github.com/libmir/dcompute">dcompute</a>というD言語でCUDAカーネルを書く謎の技術を思い出し，触ってみました．結果から言うとコンパイルすらできなかったのですが&#x2026;．いろいろ調べるとデバイス側のポインタの扱いやカーネル生成など大部分はすでにLDC本家にマージされており，若干の便利機能が残った部分がdcomputeライブラリとして残っていました．少し古いですが以下のページ
</p>

<ul class="org-ul">
<li>CUDA Driver APIのD言語ラッパー <a href="https://github.com/DerelictOrg/DerelictCUDA/blob/master/source/derelict/cuda/driverapi.d">DerelictCUDA</a></li>
<li><a href="https://github.com/ldc-developers/ldc/blob/085d9a69db42a608759aea638b388f2149dd629a/tests/codegen/dcompute_cu_addrspaces.d#L3">LDCのCUDAカーネルからのPTX生成のテストコード</a></li>
<li><a href="https://llvm.org/docs/NVPTXUsage.html#llvm-nvvm-ptr-to-gen-intrinsics">LLVMのPTXコード生成の仕組み</a></li>
<li><a href="https://llvm.org/docs/CompileCudaWithLLVM.html">ClangでCUDAバイナリをコンパイルする方法</a></li>
</ul>

<p>
を参考にしてMakefileからldc2コマンドを直に叩いてD言語からCUDAの中間コードであるPTXを生成し，dcomputeのexampleはよくわからないのでCUDA Driver APIで呼び出すことにしました．
</p>

<div class="org-src-container">
<pre class="src src-makefile"><span class="org-makefile-targets">kernel/%.ptx</span>: kernel/%.d tool/compute_capability.out
    ldc2 $<span class="org-constant">&lt;</span> --mdcompute-targets=cuda-$(<span class="org-variable-name">CUDA_COMPUTE_CAPABILITY</span>)0 -H -Hd kernel -mdcompute-file-prefix=$(<span class="org-variable-name">shell</span> basename -s .d $<span class="org-constant">&lt;</span>)
    mv $(<span class="org-variable-name">shell</span> basename -s .d $<span class="org-constant">&lt;</span>)_cuda$(<span class="org-variable-name">CUDA_COMPUTE_CAPABILITY</span>)0_$(<span class="org-variable-name">CUDA_BIT</span>).ptx <span class="org-makefile-targets">$</span><span class="org-makefile-targets"><span class="org-constant">@</span></span>
</pre>
</div>

<p>
上記のコマンドでは，PTXファイル <code>(モジュール名).ptx</code> だけでなく，D言語のヘッダー定義 <code>(モジュール名).di</code> を生成して，PTXのJITコンパイル後の関数呼び出しにおける静的型検査に使おうと考えました(これは最後まで実装していないが，<a href="https://github.com/ShigekiKarita/d-nv/blob/master/source/dnv/typechecker.d">NVRTCラッパーを作ったときに同じことを</a>以前やったので，そんなに難しくないと思います)．
</p>

<p>
この日はCUDA入門で最初にやるベクトル加算(axpy)の実装と実行まで動いています．困った点として，CUDA Driver APIにあるコンテキスト <code>cuContext</code> を破棄するタイミングが，GCより前に起こってしまい，いくつかのCUDA関係のオブジェクトのデストラクタがGCによってCUDA関係のDestroy/Free系関数を呼んでうまく開放できませんでした．簡単な解決策として， <code>cuContext</code> の破棄の前に明示的にGCを呼ぶことで回避しました．
</p>

<div class="org-src-container">
<pre class="src src-d"><span class="org-keyword">module</span> grain.<span class="org-constant">cuda</span>;

...

<span class="org-keyword">shared</span> <span class="org-keyword">static</span> ~<span class="org-keyword">this</span>() {
    <span class="org-keyword">import</span> core.<span class="org-type">memory</span> : GC;
    GC.collect();
    checkCudaErrors(cuCtxDestroy(context));
}
</pre>
</div>

<p>
3日目くらいで作業メモを残そうと思い，この文書を書き始めてタイトルには1週間と書いてみましたが，この期間は普通に働いているので一日2-5時間程度の作業時間でした．なおリポジトリは下記の通りで，git cloneしてmakeを叩けばテストまで走ります，動作していたDコンパイラは<a href="https://github.com/ldc-developers/ldc/releases/tag/v1.9.0">LDC1.9.0</a>(Linux X64)です．
</p>

<ul class="org-ul">
<li>この日の最終 commit  <a href="https://github.com/ShigekiKarita/grain/tree/54c0c6b390c3258dcb80c5868cd3304387c6abdc">https://github.com/ShigekiKarita/grain/tree/54c0c6b390c3258dcb80c5868cd3304387c6abdc</a></li>
</ul>
</div>
</div>

<div id="outline-container-org0056121" class="outline-2">
<h2 id="org0056121"><span class="section-number-2">2</span> CPUホスト・CUDAデバイスそれぞれのメモリ管理 (2日目, 5/8)</h2>
<div class="outline-text-2" id="text-2">
<p>
とりあえずCUDAは <code>CuPtr(T)</code> というホストだと <code>T[]</code> に相当するCUDA配列の構造体を作りました．この構造体はデバイス上のアドレス <code>cuDeviceptr ptr</code> と長さ <code>size_t length</code> のペアです．メソッドとしてはCPUメモリからのコピーコンストラクタ <code>this(T[] host)</code> と，デバイスメモリをコピーする <code>CuPtr!T dup()</code> を追加．(参照の)コピーコンストラクタは <code>@disable this(this);</code> として無効化しました，これは経験上GCによるCUDAデバイスメモリの管理は悲惨なことになるので&#x2026;．実際にはGCの代わりに標準ライブラリにある参照カウンタ <code>RefCounted(T)</code> を使うことで管理する方針．<a href="https://www.cs.virginia.edu/~mwb7w/cuda_support/memory_management_overhead.html">CUDAはmalloc/freeのコストが高い</a>ので，いずれはメモリプールなどを実装したいですね．
</p>

<div class="org-src-container">
<pre class="src src-d"><span class="org-keyword">struct</span> <span class="org-type">CuPtr</span>(<span class="org-type">T</span>) {
    <span class="org-keyword">import</span> derelict.<span class="org-type">cuda</span>;
    <span class="org-type">CUdeviceptr</span> <span class="org-variable-name">ptr</span>;
    <span class="org-type">size_t</span> <span class="org-variable-name">length</span>;

    <span class="org-keyword">this</span>(<span class="org-type">CUdeviceptr</span> <span class="org-variable-name">p</span>, <span class="org-type">size_t</span> <span class="org-variable-name">l</span>) {
        <span class="org-keyword">this</span>.ptr = p;
        <span class="org-keyword">this</span>.length = l;
    }

    <span class="org-keyword">this</span>(<span class="org-type">size_t</span> <span class="org-variable-name">n</span>) {
        <span class="org-keyword">this</span>.length = n;
        checkCudaErrors(cuMemAlloc(&amp;ptr, T.<span class="org-keyword">sizeof</span> * n));
    }

    <span class="org-keyword">this</span>(<span class="org-type">T</span>[] <span class="org-variable-name">host</span>) {
        <span class="org-keyword">this</span>(host.length);
        checkCudaErrors(cuMemcpyHtoD(ptr, &amp;host[0], T.<span class="org-keyword">sizeof</span> * length));
    }

    <span class="org-c-annotation">@disable</span> <span class="org-keyword">this</span>(<span class="org-keyword">this</span>); <span class="org-comment-delimiter">// </span><span class="org-comment">not copyable</span>

    ~<span class="org-keyword">this</span>() {
        checkCudaErrors(cuMemFree(ptr));
    }

    <span class="org-keyword">auto</span> <span class="org-function-name">dup</span>() {
        <span class="org-type">CUdeviceptr</span> <span class="org-variable-name">ret</span>;
        checkCudaErrors(cuMemAlloc(&amp;ret, T.<span class="org-keyword">sizeof</span> * length));
        checkCudaErrors(cuMemcpyDtoD(ret, ptr, T.<span class="org-keyword">sizeof</span> * length));
        <span class="org-keyword">return</span> <span class="org-keyword">typeof</span>(<span class="org-keyword">this</span>)(ret, length);
    }

    <span class="org-keyword">ref</span> <span class="org-type">toHost</span>(<span class="org-keyword">ref</span> <span class="org-type">T</span>[] <span class="org-variable-name">host</span>) {
        host.length = length;
        checkCudaErrors(cuMemcpyDtoH(&amp;host[0], ptr, T.<span class="org-keyword">sizeof</span> * length));
        <span class="org-keyword">return</span> host;
    }

    <span class="org-keyword">auto</span> <span class="org-function-name">toHost</span>() {
        <span class="org-keyword">auto</span> <span class="org-variable-name">host</span> = <span class="org-keyword">new</span> T[length];
        checkCudaErrors(cuMemcpyDtoH(&amp;host[0], ptr, T.<span class="org-keyword">sizeof</span> * length));
        <span class="org-keyword">return</span> host;
    }
}
</pre>
</div>

<p>
ゆくゆくはGCが管理する動的配列 <code>T[]</code> ではなく，malloc/freeで自前で管理した配列を使いたいのですが，どうせ後でMirを使うことになるので，自作はやめてGCの動的配列を使うことにしました．いずれ参照カウンタ付のmalloc/freeで確保・開放するMir配列(<a href="http://mir.dlang.io/mir_ndslice_allocation.html#stdcSlice">stdcSlice</a>)を使うことにします．
</p>

<ul class="org-ul">
<li>この日の最終 commit <a href="https://github.com/ShigekiKarita/grain/tree/e58940b2b18b921e0cc22f86511e67e245e0b13b">https://github.com/ShigekiKarita/grain/tree/e58940b2b18b921e0cc22f86511e67e245e0b13b</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgc4b66c3" class="outline-2">
<h2 id="orgc4b66c3"><span class="section-number-2">3</span> 虚無 (3日目, 5/9)</h2>
<div class="outline-text-2" id="text-3">
<p>
この日は泊りがけの出張で新幹線の中で少しだけ作業した&#x2026;気がしていたが，変数名を変えたくらいでした．ノートPCにはCUDA対応デバイスがなく，ましてOpenCLも動かす気にはならなかったので，D言語の<a href="https://dlang.org/spec/version.html">条件コンパイル</a>機能でCUDAが必要な部分を以下のように指定したいなと思った．
</p>

<div class="org-src-container">
<pre class="src src-d"><span class="org-keyword">version</span> (grain_cuda) {
   <span class="org-comment-delimiter">// </span><span class="org-comment">CUDA&#20381;&#23384;&#12398;&#12467;&#12540;&#12489;</span>
}
</pre>
</div>

<p>
どうやってユーザ定義のversionを作るのかわからなかったので，困ったときのmir-algorithmリポジトリの<a href="https://github.com/libmir/mir-algorithm/blob/master/dub.json">dub.json</a>を見ると
</p>

<div class="org-src-container">
<pre class="src src-json">...
<span class="org-keyword">"buildTypes"</span>: {
  <span class="org-keyword">"unittest"</span>: {
     <span class="org-keyword">"buildOptions"</span>: [<span class="org-string">"unittests"</span>, <span class="org-string">"debugMode"</span>, <span class="org-string">"debugInfo"</span>],
         <span class="org-keyword">"versions"</span>: [<span class="org-string">"mir_test"</span>]
  },
},
...
</pre>
</div>

<p>
という記述があり，この例では <code>mir_test</code> というversionをunittestのとき (<code>dub --build=unittest~でビルドしたとき) に有効になるという具合でした．なのでCUDAを使う部分だけ ~grain_cuda</code> のようなバージョン指定子で隔離すればCUDAのない環境でもCPU動作の部分だけ動かせると思いました．なお，その機能を実装したのは5日目．
</p>

<ul class="org-ul">
<li>この日の最終 commit <a href="https://github.com/ShigekiKarita/grain/tree/e58940b2b18b921e0cc22f86511e67e245e0b13b">https://github.com/ShigekiKarita/grain/tree/e58940b2b18b921e0cc22f86511e67e245e0b13b</a></li>
</ul>
</div>
</div>

<div id="outline-container-org38af46b" class="outline-2">
<h2 id="org38af46b"><span class="section-number-2">4</span> CPUホスト・CUDAデバイス両対応な関数オブジェクト (4日目, 5/10)</h2>
<div class="outline-text-2" id="text-4">
<p>
前日の出張のせいで風邪を引いたので全体的にダラダラと妄想しただけでした．
</p>
</div>

<div id="outline-container-org1022bc7" class="outline-3">
<h3 id="org1022bc7"><span class="section-number-3">4.1</span> Function 関数オブジェクト</h3>
<div class="outline-text-3" id="text-4-1">
<p>
4日目にしてようやくDeep learningっぽいことを考え始めるのですが，自動微分可能な関数の設計を考えました．思えば私が一番設計がシンプルで好きな(=私が理解できた)既存のフレームワークはChainerのversion 1でした．今のChainerは色々なトレードオフで，v1ほどは綺麗ではないと思います(例えばPytorchもChainer v1を参考に作られています)．Chainer v1の素晴らしかったことは
</p>

<ol class="org-ol">
<li>動的な計算グラフ(define by run)を考案した</li>
<li>ユーザ定義のFuncitonが簡単にかけた</li>
<li>全てPythonで書かれていた (デバッグやコードの拡張が簡単)</li>
</ol>

<p>
ということではないかと思うのですが，3番目の全てPythonで書かれていたというのは素晴らしくないことでもあり，静的型検査やネイティブコードの速さといった恩恵が，C++で書かれた他フレームワークのように受けられない点もまた人気が低い原因かなと思います．初日に述べたように私はC++で1,2の利点を持つライブラリを職場では作って使っているのですが，C++もときどき辛いことがあります．だからchainerのようなライブラリをD言語で作れば楽しいだろうなと思ったのです．
</p>

<p>
ところで，Chainer v1のFunctionを定義する場合はこんな感じでかけます．
</p>

<ul class="org-ul">
<li>from <a href="https://github.com/chainer/chainer/blob/v1/chainer/functions/activation/relu.py">https://github.com/chainer/chainer/blob/v1/chainer/functions/activation/relu.py</a></li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">class</span> <span class="org-type">ReLU</span>(function.Function):

    <span class="org-doc">"""Rectified Linear Unit."""</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">TODO(beam2d): Implement in-place version.</span>

    <span class="org-keyword">def</span> <span class="org-function-name">__init__</span>(<span class="org-keyword">self</span>, use_cudnn=<span class="org-constant">True</span>):
        <span class="org-keyword">self</span>.use_cudnn = use_cudnn

    <span class="org-keyword">def</span> <span class="org-function-name">check_type_forward</span>(<span class="org-keyword">self</span>, in_types):
        type_check.expect(
            in_types.size() == 1,
            in_types[0].dtype.kind == <span class="org-string">'f'</span>,
        )

    <span class="org-keyword">def</span> <span class="org-function-name">forward_cpu</span>(<span class="org-keyword">self</span>, x):
        <span class="org-keyword">return</span> utils.force_array(numpy.maximum(x[0], 0, dtype=x[0].dtype)),

    <span class="org-keyword">def</span> <span class="org-function-name">forward_gpu</span>(<span class="org-keyword">self</span>, x):
        <span class="org-keyword">if</span> (cuda.cudnn_enabled <span class="org-keyword">and</span> <span class="org-keyword">self</span>.use_cudnn <span class="org-keyword">and</span>
                x[0].flags.c_contiguous <span class="org-keyword">and</span>
                (_cudnn_version &gt;= 3000 <span class="org-keyword">or</span> x[0].dtype != numpy.float16)):
            <span class="org-variable-name">y</span> = cudnn.activation_forward(x[0], _mode)
            <span class="org-keyword">self</span>.y = y
        <span class="org-keyword">else</span>:
            <span class="org-variable-name">y</span> = cuda.cupy.maximum(x[0], 0)
        <span class="org-keyword">return</span> y,

    <span class="org-keyword">def</span> <span class="org-function-name">backward_cpu</span>(<span class="org-keyword">self</span>, x, gy):
        <span class="org-keyword">return</span> utils.force_array(gy[0] * (x[0] &gt; 0)),

    <span class="org-keyword">def</span> <span class="org-function-name">backward_gpu</span>(<span class="org-keyword">self</span>, x, gy):
        <span class="org-keyword">if</span> (cuda.cudnn_enabled <span class="org-keyword">and</span> <span class="org-keyword">self</span>.use_cudnn <span class="org-keyword">and</span>
                x[0].flags.c_contiguous <span class="org-keyword">and</span> gy[0].flags.c_contiguous <span class="org-keyword">and</span>
                (_cudnn_version &gt;= 3000 <span class="org-keyword">or</span> x[0].dtype != numpy.float16)):
            <span class="org-variable-name">gx</span> = cudnn.activation_backward(x[0], <span class="org-keyword">self</span>.y, gy[0], _mode)
        <span class="org-keyword">else</span>:
            <span class="org-variable-name">gx</span> = cuda.elementwise(
                <span class="org-string">'T x, T gy'</span>, <span class="org-string">'T gx'</span>,
                <span class="org-string">'gx = x &gt; 0 ? gy : (T)0'</span>,
                <span class="org-string">'relu_bwd'</span>)(x[0], gy[0])
        <span class="org-keyword">return</span> gx,
</pre>
</div>

<p>
これを真似して，こんな感じで書こうと思います．
</p>

<div class="org-src-container">
<pre class="src src-d"><span class="org-keyword">class</span> <span class="org-type">ReLU</span>(<span class="org-type">T</span>, <span class="org-type">size_t</span> <span class="org-variable-name">dim</span>) : Function <span class="org-keyword">if</span> (isFloatingPoint<span class="org-negation-char">!</span>T) {
    <span class="org-type">bool</span> <span class="org-variable-name">inplace</span> = <span class="org-constant">false</span>;

    <span class="org-keyword">auto</span> <span class="org-function-name">forward</span>(Variable<span class="org-negation-char">!</span>(<span class="org-type">T</span>, <span class="org-type">dim</span>, <span class="org-type">HostStorage</span>) x) {
        <span class="org-keyword">import</span> mir.<span class="org-type">ndslice</span> : each;
        <span class="org-keyword">auto</span> <span class="org-variable-name">y</span> = <span class="org-keyword">this</span>.inplace ? x : x.dup;
        y.sliced.each<span class="org-negation-char">!</span>((<span class="org-keyword">ref</span> <span class="org-type">a</span>) { <span class="org-keyword">if</span> (a &lt; 0) a = 0; });
        <span class="org-keyword">return</span> y;
    }

    <span class="org-keyword">auto</span> <span class="org-function-name">backward</span>(Variable<span class="org-negation-char">!</span>(<span class="org-type">T</span>, <span class="org-type">dim</span>, <span class="org-type">HostStorage</span>) gy, Variable<span class="org-negation-char">!</span>(<span class="org-type">T</span>, <span class="org-type">dim</span>, <span class="org-type">HostStorage</span>) x) {
        <span class="org-keyword">auto</span> <span class="org-variable-name">gx</span> = gy.dup;
        <span class="org-keyword">foreach</span> (i; 0..gx.data.length) {
            <span class="org-keyword">if</span> (x.data[i] &lt; 0.0) gx.data[i] = 0.0;
        }
        <span class="org-keyword">return</span> gx;
    }

    <span class="org-keyword">version</span>(grain_cuda) {
        <span class="org-keyword">auto</span> <span class="org-function-name">forward</span>(Variable<span class="org-negation-char">!</span>(<span class="org-type">T</span>, <span class="org-type">dim</span>, <span class="org-type">DeviceStorage</span>) x) {
            <span class="org-keyword">import</span> grain.<span class="org-type">kernel</span> : relu;
            <span class="org-keyword">auto</span> <span class="org-variable-name">y</span> = <span class="org-keyword">this</span>.inplace ? x : x.dup;
            <span class="org-keyword">auto</span> <span class="org-variable-name">n</span> = <span class="org-keyword">cast</span>(<span class="org-type">uint</span>) y.data.length;
            Global.kernel<span class="org-negation-char">!</span>relu
                .launch(y.data.ptr, n, [1,1,1], [n,1,1]);
            <span class="org-keyword">return</span> y;
        }

        <span class="org-keyword">auto</span> <span class="org-function-name">backward</span>(Variable<span class="org-negation-char">!</span>(<span class="org-type">T</span>, <span class="org-type">dim</span>, <span class="org-type">DeviceStorage</span>) gy, Variable<span class="org-negation-char">!</span>(<span class="org-type">T</span>, <span class="org-type">dim</span>, <span class="org-type">DeviceStorage</span>) x) {
            <span class="org-keyword">import</span> grain.<span class="org-type">kernel</span> : reluGrad;
            <span class="org-keyword">auto</span> <span class="org-variable-name">gx</span> = CuPtr<span class="org-negation-char">!</span>T(gy.data.length);
            <span class="org-keyword">auto</span> <span class="org-variable-name">n</span> = <span class="org-keyword">cast</span>(<span class="org-type">uint</span>) gy.data.length;
            Global.kernel<span class="org-negation-char">!</span>reluGrad
                .launch(gx.data.ptr, gy.data.ptr, x.data.ptr, n, [1,1,1], [n,1,1]);
            <span class="org-keyword">return</span> gx;
        }
    }
}
</pre>
</div>

<p>
ここで， <code>struct Variable(T, size_t dim, alias Storage)</code> という構造体は自動微分可能な多次元配列で，要素型(float, intなど) <code>T</code> と多次元配列の次元数(スカラ=0, ベクトル=1, 行列=2, &#x2026;), メモリの種類(CPUメモリ=HostStorage, CUDAメモリ=DeviceStorage)という型変数を持っています．Pythonと違って次元が合わないといった実行時エラーはおきません．ただし経験上，行や列などのサイズまで静的に指定するのは使いにくいのでやめました．もしかするとMirのndsliceのようにContiguousかどうかは静的に決まるので型に入れた方がパフォーマンス的に良いかもしれないですね．
</p>

<p>
あと <code>import grain.kernel : relu;</code> はD言語で書かれたカーネルのヘッダー定義で，元のコードはこんな感じで<a href="https://github.com/ShigekiKarita/grain/blob/8825341f9a1986d1916d6433ec4dd26562f2d977/kernel/kernel.d">kernel/kernel.d</a>に定義されています．
</p>

<div class="org-src-container">
<pre class="src src-d"><span class="org-c-annotation">@kernel</span> <span class="org-type">void</span> <span class="org-function-name">relu</span>(GlobalPointer<span class="org-negation-char">!</span><span class="org-type">float</span> x, <span class="org-type">size_t</span> <span class="org-variable-name">N</span>) {
    <span class="org-keyword">auto</span> <span class="org-variable-name">i</span> = GlobalIndex.x;
    <span class="org-keyword">if</span> (i &gt;= N) <span class="org-keyword">return</span>;
    <span class="org-keyword">if</span> (x[i] &lt; 0) x[i] = 0;
}
</pre>
</div>

<p>
メリットとしては，デバイスのカーネル実装含めてD言語で全部シンプルに書かれている点と，きちんと引数の型が静的にチェックされるという点です．Deep learningのように何日も掛かる処理で実行時の型エラーに悩まされたくないのです&#x2026;．
</p>
</div>
</div>

<div id="outline-container-org259964c" class="outline-3">
<h3 id="org259964c"><span class="section-number-3">4.2</span> BLASライブラリの導入</h3>
<div class="outline-text-3" id="text-4-2">
<p>
さすがに自前で行列演算までは実装したくないので，Mirの人が作ってくれたndslice用のBLASラッパー<a href="https://github.com/kaleidicassociates/lubeck">lubeck</a>と，以前に作った<a href="https://github.com/ShigekiKarita/d-nv/blob/7946c12c5657d0a9e73167792d1565f2f1474e86/source/dnv/cuda/cublas.d#L1">cuBLASラッパー</a>を使うことにしました．CPU用のBLASのバックエンドは<a href="https://shigekikarita.github.io/blog/2017/10/27/001.html">経験的に速いIntel MKL</a>を使います．
</p>

<ul class="org-ul">
<li>この日の最終 commit (とくに変更はない) <a href="https://github.com/ShigekiKarita/grain/tree/e58940b2b18b921e0cc22f86511e67e245e0b13b">https://github.com/ShigekiKarita/grain/tree/e58940b2b18b921e0cc22f86511e67e245e0b13b</a></li>
</ul>
</div>
</div>
</div>


<div id="outline-container-org83d5131" class="outline-2">
<h2 id="org83d5131"><span class="section-number-2">5</span> シンプルな自動微分メカニズムと型消去 (5日目, 5/11)</h2>
<div class="outline-text-2" id="text-5">
<p>
出張先の神奈川が京都と比べて寒すぎた．風邪を引いて一日中寝てたので，大まかな設計を考えて，3,4日目に考えたCUDA依存の条件コンパイルと自動微分関数(ReLU, MatMul)を実装した．
</p>
</div>

<div id="outline-container-orgab11bde" class="outline-3">
<h3 id="orgab11bde"><span class="section-number-3">5.1</span> 自動微分の仕組み</h3>
<div class="outline-text-3" id="text-5-1">
<p>
多層ニューラルネットワークの自動微分は，合成関数の導関数=<a href="https://ja.wikipedia.org/wiki/%E9%80%A3%E9%8E%96%E5%BE%8B">微分の連鎖律</a>によって成り立っている．
</p>

\begin{align}
y &= f(g(x)) \\
\frac{\partial f}{\partial x} &= \frac{\partial f}{\partial g}\frac{\partial g}{\partial x}
\end{align}

<p>
例えば一層目のニューラルネットワーク(=パラメータ行列によるアフィン変換とReLUなどの非線形変換の合成関数)を \(g\), 二層目を \(f\) と書くと，損失関数をLとすると入力 \(x\) に対する損失値は \(L(f(g(x)))\) として表されます．このような多層ニューラルネットに対して損失値を最小化するためには backprop と呼ばれる効率的なアルゴリズムがあります．
</p>

<ul class="org-ul">
<li>二層目を \(f(x) -= \frac{\partial L}{\partial f}\) となるように，さらに連鎖律でアフィン変換のパラメータ行列の勾配までもとめて更新する．</li>
<li>一層目を \(g(x) -= \frac{\partial L}{\partial f}\frac{\partial f}{\partial g}\) となるように更新する．ここで， \(\frac{\partial L}{\partial f}\) は二層で求めた値なので，そのまま効率よく使いまわせます．この手順を逆伝搬=backpropといいます．</li>
</ul>

<p>
backpropに必要な実装として，
</p>

<ul class="org-ul">
<li>\(L(f(g(x)))\) のように変数が L &lt;- f &lt;- g として作られてきた連鎖の履歴として有向グラフ(複数の変数から1つの変数が作られたりするのでリストではない)の保存する仕組み</li>
<li>各関数(e.g., \(f\) )における伝搬してきた損失値の出力値に対する微分 (e.g., \(\frac{\partial L}{\partial f}\)) から入力値に対する微分 (e.g., \(\frac{\partial L}{\partial f}\frac{\partial f}{\partial g}\)) をもらって受け渡す仕組み．</li>
</ul>

<p>
以上から昨日chainerの例と共に出した，Function の forward 関数の正体は入力から出力を計算し，backward 関数は二番目の出力の微分から入力の微分を返す関数でした．
</p>
</div>
</div>

<div id="outline-container-org02bffe5" class="outline-3">
<h3 id="org02bffe5"><span class="section-number-3">5.2</span> 変数 Variable の仕組み</h3>
<div class="outline-text-3" id="text-5-2">
<p>
上記の二箇所は <code>Variable(T, size_t dim, alias Storage)</code> の中に実装することになりますが，履歴の有向グラフの型が問題になります．Variableは次元 <code>dim</code> などを様々な型変数に持つために，
</p>

<div class="org-src-container">
<pre class="src src-d"><span class="org-keyword">struct</span> <span class="org-type">Variable</span>(<span class="org-type">T</span>, <span class="org-type">size_t</span> <span class="org-variable-name">dim</span>, <span class="org-keyword">alias</span> <span class="org-type">Storage</span>, <span class="org-type">Args</span>...) {
  <span class="org-type">Function</span> <span class="org-variable-name">func</span>; <span class="org-comment-delimiter">// </span><span class="org-comment">&#21512;&#25104;&#20803;&#12398;&#38306;&#25968;</span>
  Tuple<span class="org-negation-char">!</span>(<span class="org-type">Args</span>) args; <span class="org-comment-delimiter">// </span><span class="org-comment">&#21512;&#25104;&#20803;&#12398;&#38306;&#25968;&#12398;&#20837;&#21147;</span>
  RefCounted<span class="org-negation-char">!</span>(Storage<span class="org-negation-char">!</span>T) data, grad;
}
</pre>
</div>

<p>
として，書くと動的にグラフを作る再帰NNなどの例を考えると，2回再帰したあとのVariableと，3回再帰した後のVariableで型が変わるわけです．TheanoのようにScanなどの特殊な型を作れば解決できますが，さすがに使い勝手が悪いので，うまく型消去した型 <code>struct UntypedVariable</code> を作ります．
</p>

<div class="org-src-container">
<pre class="src src-d"><span class="org-keyword">struct</span> <span class="org-type">UntypedVariable</span> {
    <span class="org-keyword">import</span> std.<span class="org-type">variant</span> : Variant;
    <span class="org-type">size_t</span> <span class="org-variable-name">dim</span>;
    <span class="org-type">size_t</span>[] <span class="org-variable-name">shape</span>;
    <span class="org-type">ptrdiff_t</span>[] <span class="org-variable-name">strides</span>;
    <span class="org-type">bool</span> <span class="org-variable-name">isHost</span>;
    <span class="org-type">TypeInfo</span> <span class="org-variable-name">elem</span>;
    <span class="org-type">Variant</span> <span class="org-variable-name">data</span>, <span class="org-variable-name">grad</span>; <span class="org-comment-delimiter">// </span><span class="org-comment">&#22411;&#28040;&#21435;&#12375;&#12383; HostStorage!T &#12414;&#12383;&#12399; DeviceStorage!T</span>
}
</pre>
</div>


<ul class="org-ul">
<li>この日の最終 commit (構想だけに終わって実装できてないところも多い) <a href="https://github.com/ShigekiKarita/grain/tree/8825341f9a1986d1916d6433ec4dd26562f2d977">https://github.com/ShigekiKarita/grain/tree/8825341f9a1986d1916d6433ec4dd26562f2d977</a></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgc0bc52d" class="outline-2">
<h2 id="orgc0bc52d"><span class="section-number-2">6</span> BackPropの実装とテスト (6日目, 5/12)</h2>
<div class="outline-text-2" id="text-6">
<p>
この日は風邪が治ってきたので，実際に微分可能な変数と関数を実装して動かした．
昨日の続きで，関数の型消去&#x2026;ではなく，関数のbackward関数を型消去したdelegateと必要な引数を集めるBackProp構造体を作ります．
</p>
</div>

<div id="outline-container-org8c52218" class="outline-3">
<h3 id="org8c52218"><span class="section-number-3">6.1</span> BackProp の実装</h3>
<div class="outline-text-3" id="text-6-1">
<p>
先日のFunctionを継承したReLUの実装には問題がありました． <code>class</code> を使っているので， <code>Function</code> が持つGPU配列が結局GCの管理下におかれてしまっています．ただ最初の実装として，完璧である必要はないのでとりあえずテストできる動くものを作った訳です．C++のように効率の追求もできるけど，簡単にプロトタイピングもできるのがD言語のいいところですね．
</p>

<p>
解決策としては，冒頭に述べたような関数オブジェクトの backward 関数に出力の微分値リスト(<code>UntypedVariable[]</code>)を適用して，入力の微分値リスト(<code>UntypedVariable[]</code>)を返すdelegateのような <code>BackProp</code> オブジェクトを参照カウンタで管理すれば良いわけです．以上をまとめるとこんな感じの相互再帰みたいにかけます．
</p>

<div class="org-src-container">
<pre class="src src-d"><span class="org-keyword">struct</span> <span class="org-type">UntypedVariable</span> {
  ...
  RefCounted<span class="org-negation-char">!</span>BackProp <span class="org-variable-name">bprop</span>;
  <span class="org-comment-delimiter">// </span><span class="org-comment">&#20986;&#21147;&#12373;&#12428;&#12383;&#22793;&#25968;&#12398;tuple&#20013;&#12398;&#20301;&#32622;</span>
  <span class="org-type">size_t</span> <span class="org-variable-name">outPosition</span> = 0;

  <span class="org-comment-delimiter">// </span><span class="org-comment">loss &#12398;&#12424;&#12358;&#12394; backprop &#12398;&#36215;&#28857;&#12399; gradOutput &#12364; null</span>
  <span class="org-type">void</span> <span class="org-function-name">backward</span>(<span class="org-type">UntypedVariable</span>* <span class="org-variable-name">gradOutput</span>=<span class="org-constant">null</span>) {
    <span class="org-keyword">if</span> (bprop.refCountedStore.isInitialized) {
      bprop.backward(outPosition, gradOutput);
    }
  }
}

<span class="org-keyword">struct</span> <span class="org-type">BackProp</span> {
  <span class="org-comment-delimiter">// </span><span class="org-comment">&#21512;&#25104;&#20803;&#12398;&#36870;&#20253;&#25644;&#38306;&#25968; (ReLU&#12398;backward&#12395;</span>
  <span class="org-type">UntypedVariable</span>[] <span class="org-type">delegate</span>(<span class="org-type">UntypedVariable</span>[]) proc;
  <span class="org-comment-delimiter">// </span><span class="org-comment">&#20986;&#21147;&#20516;&#12398;&#24494;&#20998; (forward&#26178;&#12395;&#20986;&#21147;tuple&#12398;&#35201;&#32032;&#25968;&#12391;&#21021;&#26399;&#21270;&#12373;&#12428;&#12427;)</span>
  <span class="org-type">UntypedVariable</span>[] <span class="org-variable-name">gradOutputs</span>;
  <span class="org-comment-delimiter">// </span><span class="org-comment">&#21512;&#25104;&#20803;&#12398;&#38306;&#25968;&#12398;&#20837;&#21147; (&#21021;&#26399;&#21270;&#12399;&#12373;&#12428;&#12394;&#12356;)</span>
  <span class="org-type">UntypedVariable</span>[] <span class="org-variable-name">inputs</span>;
  <span class="org-comment-delimiter">// </span><span class="org-comment">&#21463;&#12369;&#21462;&#12387;&#12383; gradOutputs &#12398;&#25968;</span>
  <span class="org-type">size_t</span> <span class="org-variable-name">nGrad</span> = 0;

  <span class="org-type">void</span> <span class="org-function-name">backward</span>(<span class="org-type">size_t</span> <span class="org-variable-name">pos</span>, <span class="org-type">UntypedVariable</span>* <span class="org-variable-name">grad</span>) {
    <span class="org-keyword">if</span> (grad <span class="org-keyword">is</span> <span class="org-constant">null</span>) {
      enforce(gradOutputs.empty, <span class="org-string">"this variable is not loss"</span>);
    } <span class="org-keyword">else</span> {
      ++nGrad;
      gradOutputs[pos] = grad;
    }
    <span class="org-comment-delimiter">// </span><span class="org-comment">&#20986;&#21147;&#20516;&#12398;&#20840;&#12390;&#12398;&#24494;&#20998;&#12364;&#38598;&#12414;&#12387;&#12383;</span>
    <span class="org-keyword">if</span> (grad <span class="org-keyword">is</span> <span class="org-constant">null</span> || nGrad + 1 == gradOutputs.length) {
      <span class="org-keyword">auto</span> <span class="org-variable-name">gradInputs</span> = proc(gradOutputs);
      <span class="org-keyword">foreach</span> (i; 0..inputs.length) {
        <span class="org-type">inputs</span>[i].<span class="org-function-name">backward</span>(<span class="org-type">gradInputs</span>[i]);
      }
    }
  }
}
</pre>
</div>

<p>
イメージとしては BackPropの起点の <code>Variable!(...) loss</code> (損失値) から, <code>gradOutput = [1]</code> として逆伝搬できます．
</p>
</div>
</div>
</div>


<div id="outline-container-org953999b" class="outline-2">
<h2 id="org953999b"><span class="section-number-2">7</span> 手書き文字認識MNISTの実行 (7日目, 5/13)</h2>
<div class="outline-text-2" id="text-7">
<p>
ここまでできたらあとはSoftMaxCrossEntropy関数などを実装して<a href="https://twitter.com/fchollet/status/807198327288791040">Deep LearningのUnit Testといわれる手書き文字認識MNIST</a>を動かします．
</p>

<p>
注：後日6/8に動くようになったようです． 1週間くらいでモチベーションが消えてきて，実際は1ヶ月かかってしまった．笑
</p>

<p>
<a href="https://github.com/ShigekiKarita/grain/blob/5c5d6226e153ebcb6debd1d923783a2b7de53eaa/example/mnist.d">https://github.com/ShigekiKarita/grain/blob/5c5d6226e153ebcb6debd1d923783a2b7de53eaa/example/mnist.d</a>
</p>
</div>
</div>

<div id="outline-container-orgc09d6b1" class="outline-2">
<h2 id="orgc09d6b1"><span class="section-number-2">8</span> <span class="todo TODO">TODO</span> 残った課題</h2>
<div class="outline-text-2" id="text-8">
<ul class="org-ul">
<li>カーネル引数の静的型チェック</li>
<li>GC配列をMirのstdcSliceへの置き換え</li>
<li>遅延評価による静的グラフの最適化</li>
<li>UntypedVariableからVariableへの動的型チェック (後日やりました)</li>
<li>cuDNNとCNNのサポート (後日やりました)</li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">&#33879;&#32773;: Shigeki Karita</p>
<p class="date">Created: 2018-12-01 土 16:46</p>
<p class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 26.1 (<a href="https://orgmode.org">Org</a> mode 9.1.9)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
